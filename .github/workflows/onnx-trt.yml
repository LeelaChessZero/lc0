name: ONNX-TensorRT Backend Build

on:
  workflow_call:
    inputs:
      os:
        required: true
        type: string
      artifact_name:
        required: true
        type: string

jobs:
  build:
    runs-on: ${{ inputs.os }}
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      - name: Update submodules
        run: |
          git submodule sync --recursive
          git submodule update --init --recursive
      - name: Install Build Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y ninja-build curl binutils python3-pip
          pip3 install meson==1.3.2
          meson --version
      - name: Install .NET SDK
        run: |
          wget https://dot.net/v1/dotnet-install.sh -O dotnet-install.sh
          chmod +x dotnet-install.sh
          ./dotnet-install.sh --version latest
          echo "$HOME/.dotnet" >> $GITHUB_PATH
          dotnet --version
             
      - name: Install CUDA.12 and TensorRT Dependencies
        run: |
          if [ "${{ inputs.os }}" == "ubuntu-22.04" ]; then
             wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
             sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
             wget https://developer.download.nvidia.com/compute/cuda/12.9.1/local_installers/cuda-repo-ubuntu2204-12-9-local_12.9.1-575.57.08-1_amd64.deb
             sudo dpkg -i cuda-repo-ubuntu2204-12-9-local_12.9.1-575.57.08-1_amd64.deb
             sudo cp /var/cuda-repo-ubuntu2204-12-9-local/cuda-*-keyring.gpg /usr/share/keyrings/
             sudo apt-get update
             sudo apt-get -y install cuda-toolkit-12-9
             sudo apt-get update
          else
             wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-ubuntu2404.pin
             sudo mv cuda-ubuntu2404.pin /etc/apt/preferences.d/cuda-repository-pin-600
             wget https://developer.download.nvidia.com/compute/cuda/12.9.1/local_installers/cuda-repo-ubuntu2404-12-9-local_12.9.1-575.57.08-1_amd64.deb
             sudo dpkg -i cuda-repo-ubuntu2404-12-9-local_12.9.1-575.57.08-1_amd64.deb
             sudo cp /var/cuda-repo-ubuntu2404-12-9-local/cuda-*-keyring.gpg /usr/share/keyrings/
             sudo apt-get update
             sudo apt-get -y install cuda-toolkit-12-9
             sudo apt-get update
          fi
      - name: Install ONNX Runtime GPU
        run: |
          # Create a temporary project to pull the NuGet package          
          dotnet new console -o dummy_onnx_project
          cd dummy_onnx_project
          # Add the correct Linux GPU package (note: Microsoft.ML.OnnxRuntime.Gpu.Linux)
          dotnet add package Microsoft.ML.OnnxRuntime.Gpu.Linux --version 1.22.1
          dotnet restore
          # Go to the global NuGet cache
          cd ~/.nuget/packages/microsoft.ml.onnxruntime.gpu.linux/1.22.1
          # Verify the layout
          echo "Contents of NuGet package:"
          ls -R
          # Install headers (if present)
          if [ -d "buildTransitive/native/include" ]; then
            sudo mkdir -p /usr/local/include/onnxruntime
            sudo cp -r buildTransitive/native/include/* /usr/local/include/onnxruntime/
          fi
          # Install shared library
          if [ -d "runtimes/linux-x64/native" ]; then
            sudo mkdir -p /usr/local/lib
            sudo cp -v runtimes/linux-x64/native/* /usr/local/lib/
          fi
          # Update library cache
          sudo ldconfig
          export ONNX_INCLUDE_PATH=/usr/local/include/onnxruntime/
          export ONNX_LIB_PATH=/usr/local/lib/
          echo "ONNX_INCLUDE_PATH=$ONNX_INCLUDE_PATH" >> $GITHUB_ENV
          echo "ONNX_LIB_PATH=$ONNX_LIB_PATH" >> $GITHUB_ENV
          cd ..
      - name: Remove Build Directory
        run: |
          echo "Cleaning old build..."
          rm -rf build
      - name: Configure Meson and Build ONNX-TensorRT
        run: |
          meson setup --buildtype release build \
                      -Dgtest=false -Dnative_arch=false \
                      -Donnx_libdir=${ONNX_LIB_PATH} \
                      -Donnx_include=${ONNX_INCLUDE_PATH}
          ninja -C build -v
      - name: Upload Meson Log on Failure
        if: failure()
        uses: actions/upload-artifact@v4.4.3
        with:
          name: build-logs-${{ inputs.artifact_name }}
          path: build
      - name: Download Network
        if: success()
        run: |
          cd build
          curl -L https://training.lczero.org/get_network?sha=195b450999e874d07aea2c09fd0db5eff9d4441ec1ad5a60a140fe8ea94c4f3a -o T79.pb.gz
          touch -t 201801010000.00 T79.pb.gz
      - name: Upload a Build Artifact
        if: success()
        uses: actions/upload-artifact@v4.4.3
        with:
          name: lc0-${{ inputs.artifact_name }}
          path: |
            build/lc0
            build/T79.pb.gz
